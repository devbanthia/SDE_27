{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XIerLl8RXNX"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_entity_text(entity):\n",
        "    # Remove text after and including first digit\n",
        "    match = re.search(r'\\d', entity)\n",
        "    if match:\n",
        "        return entity[:match.start()].strip()\n",
        "    else:\n",
        "        return entity.strip()\n",
        "\n",
        "def split_name(entity_string):\n",
        "    if pd.isna(entity_string) or not isinstance(entity_string, str) or entity_string.strip() == '':\n",
        "\n",
        "      return []\n",
        "\n",
        "    entities = str(entity_string).split('^')\n",
        "    parsed_entities = []\n",
        "\n",
        "    for entity in entities:\n",
        "        entity = clean_entity_text(entity)\n",
        "        if not entity:\n",
        "            continue\n",
        "\n",
        "        entity = entity.strip()\n",
        "\n",
        "        if ',' in entity:\n",
        "            # Handle \"Last, First Middle\" case\n",
        "            parts = entity.split(',', 1)\n",
        "            last = parts[0].strip()\n",
        "            first_middle = parts[1].strip()\n",
        "        else:\n",
        "            # Regular parsing\n",
        "            words = entity.split()\n",
        "            if not words:\n",
        "                continue\n",
        "\n",
        "            last_word = words[-1]\n",
        "            if '.' in last_word:\n",
        "                dot_parts = last_word.split('.')\n",
        "                if len(dot_parts) == 2 and dot_parts[0] and dot_parts[1]:\n",
        "                    first_middle = ' '.join(words[:-1] + [dot_parts[0]])\n",
        "                    last = dot_parts[1]\n",
        "                else:\n",
        "                    first_middle = ' '.join(words[:-1])\n",
        "                    last = last_word\n",
        "            else:\n",
        "                if len(words) == 1:\n",
        "                    first_middle = ''\n",
        "                    last = words[0]\n",
        "                else:\n",
        "                    first_middle = ' '.join(words[:-1])\n",
        "                    last = words[-1]\n",
        "\n",
        "        parsed_entities.append({'first_middle': first_middle, 'last': last, 'non_individual': np.nan })\n",
        "\n",
        "    return parsed_entities\n",
        "\n",
        "def split_non_individual(entity_string):\n",
        "    if pd.isna(entity_string) or not isinstance(entity_string, str) or entity_string.strip() == '':\n",
        "\n",
        "       return []\n",
        "\n",
        "    entities = str(entity_string).split('^')\n",
        "    parsed_entities = []\n",
        "\n",
        "    for entity in entities:\n",
        "        entity = entity.strip()\n",
        "        if not entity:\n",
        "            continue\n",
        "\n",
        "        parsed_entities.append({\n",
        "            'first_middle': np.nan,\n",
        "            'last': np.nan,\n",
        "            'non_individual': entity\n",
        "        })\n",
        "\n",
        "    return parsed_entities\n",
        "\n",
        "\n",
        "def flatten_list_of_dicts(dict_list, party):\n",
        "\n",
        "    flat_dict = {}\n",
        "    for i, d in enumerate(dict_list):\n",
        "        suffix = f'.{i}'\n",
        "        for k, v in d.items():\n",
        "            new_key = k\n",
        "            flat_dict[f\"{party}_{new_key}{suffix}\"] = v\n",
        "    return flat_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "party = \"buyer\"\n",
        "combined_df['BUYER NAME PARSED'] = combined_df['BUYER NAME'].apply(split_name)\n",
        "combined_df['BUYER ORG PARSED'] = combined_df['BUYER ORG'].apply(split_non_individual)\n",
        "combined_df['BUYER PARSED COMBINED'] = (combined_df['BUYER ORG PARSED'] + combined_df['BUYER NAME PARSED'])\n",
        "combined_df['BUYER PARSED'] = combined_df['BUYER PARSED COMBINED'].apply(lambda x: flatten_list_of_dicts(x, party))\n",
        "\n",
        "party = \"seller\"\n",
        "combined_df['SELLER NAME PARSED'] = combined_df['SELLER NAME'].apply(split_name)\n",
        "combined_df['SELLER ORG PARSED'] = combined_df['SELLER ORG'].apply(split_non_individual)\n",
        "combined_df['SELLER PARSED COMBINED'] = (combined_df['SELLER ORG PARSED'] + combined_df['SELLER NAME PARSED'])\n",
        "combined_df['SELLER PARSED'] = combined_df['SELLER PARSED COMBINED'].apply(lambda x: flatten_list_of_dicts(x, party))\n"
      ],
      "metadata": {
        "id": "KsK-Zvy4R751"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_buyer_df = pd.DataFrame(combined_df['BUYER PARSED'].tolist())\n",
        "parsed_seller_df = pd.DataFrame(combined_df['SELLER PARSED'].tolist())\n",
        "\n",
        "combined_df = pd.concat([combined_df.reset_index(drop=True), parsed_buyer_df.reset_index(drop=True), parsed_seller_df.reset_index(drop=True)], axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "j_4DZYBqSDuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# empty_count = combined_df['SELLER PARSED'].apply(lambda x: isinstance(x, dict) and len(x) == 0).sum()\n",
        "# print(f\"Number of empty dictionaries: {empty_count}\")\n",
        "\n",
        "# empty_both = combined_df.apply(\n",
        "#     lambda row: isinstance(row['SELLER NAME PARSED'], list) and len(row['SELLER NAME PARSED']) == 0 and\n",
        "#                 isinstance(row['SELLER ORG PARSED'], list) and len(row['SELLER ORG PARSED']) == 0,\n",
        "#     axis=1\n",
        "# ).sum()\n",
        "\n",
        "# print(combined_df['SELLER PARSED'])\n",
        "name_cols = ['seller_first_middle.0', 'seller_first_middle.1']\n",
        "org_cols = ['seller_non_individual.0', 'seller_non_individual.1','seller_non_individual.2']\n",
        "\n",
        "non_empty_count = parsed_seller_df[org_cols].apply(\n",
        "    lambda row: any((pd.notna(x) and str(x).strip() != '') for x in row),\n",
        "    axis=1\n",
        ").sum()\n",
        "\n",
        "\n",
        "columns = ['buyer_first_middle.0', 'buyer_first_middle.1', 'buyer_non_individual.0']\n",
        "\n",
        "combined_df['tutu'] = combined_df[columns].apply(lambda row: ' '.join(str(x).strip() for x in row if pd.notna(x) and str(x).strip() != ''), axis=1)\n",
        "# blank_count = combined_df['tutu'].apply(lambda x: str(x).strip() == '').sum()\n",
        "# print(f\"Number of blank entries in 'tutu': {blank_count}\")\n",
        "\n",
        "print(combined_df[['buyer_first_middle.0', 'buyer_last.0', 'buyer_non_individual.0']].to_string())"
      ],
      "metadata": {
        "id": "-nWWWrwiSVs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buyer_name_cols = ['BuyerFirstMiddleName', 'BuyerLastName', 'BuyerFirstMiddleName.1', 'BuyerLastName.1', 'BuyerNonIndividualName', 'BuyerNonIndividualName.1' ]\n",
        "seller_name_cols = ['SellerFirstMiddleName', 'SellerLastName', 'SellerFirstMiddleName.1', 'SellerLastName.1', 'SellerNonIndividualName', 'SellerNonIndividualName.1' ]\n",
        "predicted_buyer_name_cols = ['buyer_first_middle.0', 'buyer_last.0','buyer_first_middle.1', 'buyer_last.1', 'buyer_non_individual.0', 'buyer_non_individual.1' ]\n",
        "predicted_seller_name_cols = ['seller_first_middle.0', 'seller_last.0','seller_first_middle.1', 'seller_last.1', 'seller_non_individual.0', 'seller_non_individual.1' ]\n",
        "\n",
        "buyer_name_cols = ['BuyerFirstMiddleName', 'BuyerLastName', 'BuyerFirstMiddleName.1', 'BuyerLastName.1' ]\n",
        "seller_name_cols = ['SellerFirstMiddleName', 'SellerLastName', 'SellerFirstMiddleName.1', 'SellerLastName.1' ]\n",
        "\n",
        "predicted_buyer_name_cols = ['buyer_first_middle.0', 'buyer_last.0','buyer_first_middle.1', 'buyer_last.1']\n",
        "predicted_seller_name_cols = ['seller_first_middle.0', 'seller_last.0','seller_first_middle.1', 'seller_last.1']\n",
        "\n",
        "\n",
        "\n",
        "def rows_with_any_match_lowercase(df, list1, list2, count_nan_matches=True):\n",
        "    def row_match(row):\n",
        "\n",
        "        for col1 in list1:\n",
        "            for col2 in list2:\n",
        "                val1 = row[col1]\n",
        "                val2 = row[col2]\n",
        "                if pd.notna(val1) and pd.notna(val2):\n",
        "                    if str(val1).strip().lower() == str(val2).strip().lower():\n",
        "                        return True\n",
        "\n",
        "        if count_nan_matches:\n",
        "            if all(pd.isna(row[col]) for col in list1) and all(pd.isna(row[col]) for col in list2):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    return df.apply(row_match, axis=1)\n",
        "\n",
        "\n",
        "match_mask = rows_with_any_match_lowercase(combined_df, predicted_seller_name_cols, seller_name_cols)\n",
        "df_no_match = combined_df[~match_mask]\n",
        "print(match_mask.sum())\n",
        "print(df_no_match[seller_name_cols + predicted_seller_name_cols].head(800).to_string())"
      ],
      "metadata": {
        "id": "cWIB5LZvSZ5f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}