{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YVthvdU7gC5"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def find_date_time(text):\n",
        "\n",
        "  date_pattern = r\"(?:\\b(?:19|20)\\d{2}[-/.](?:0?[1-9]|1[0-2])[-/.](?:0?[1-9]|[12]\\d|3[01])\\b)|(?:\\b(?:0?[1-9]|1[0-2])[-/.](?:0?[1-9]|[12]\\d|3[01])[-/.](?:19|20)\\d{2}\\b)|(?:\\b(?:0?[1-9]|[12]\\d|3[01])[-/.](?:0?[1-9]|1[0-2])[-/.](?:19|20)\\d{2}\\b)|(?:\\b(?:0?[1-9]|[12]\\d|3[01])(?:st|nd|rd|th)?(?:\\s*of)?[\\s-]+(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)[\\s-]*(?:\\d{4})?\\b)|(?:\\b(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)[\\s-]+(?:0?[1-9]|[12]\\d|3[01])(?:st|nd|rd|th)?(?:[\\s,-]*\\d{4})?\\b)|(?:\\b\\d{4}[\\s,-]+(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)[\\s,-]+(?:0?[1-9]|[12]\\d|3[01])(?:st|nd|rd|th)?\\b)|(?:\\b(?:0?[1-9]|[12]\\d|3[01])\\.(?:0?[1-9]|1[0-2])\\.(?:19|20)\\d{2}\\b)\"\n",
        "  time_pattern = r\"(?:[01]?\\d|2[0-3]):[0-5]\\d(?::[0-5]\\d)?(?:\\s*[APap][Mm])?|\\b(?:[1-9]|1[0-2])(?:[:.][0-5]\\d){1,2}\\s*[APap][Mm]\\b\"\n",
        "\n",
        "  date_time_separator = r\"\\s*-\\s*|\\s+at\\s+|\\s*,\\s*|\\s*\"\n",
        "  date_time_pattern = rf\"(?:{date_pattern})(?:{date_time_separator})(?:{time_pattern})\"\n",
        "\n",
        "\n",
        "  comma_separator = r\"\\s*,\\s*\"\n",
        "  and_separator = r\"\\s*and\\s*\"\n",
        "\n",
        "  word_separator = rf\"(?:{comma_separator}|{and_separator}|\\s+)\"\n",
        "\n",
        "  return re.search(date_time_pattern, text, re.IGNORECASE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def match_keywords(context):\n",
        "    context_str = ' '.join(context).lower()\n",
        "\n",
        "    if \"vendor's\" in context_str and \"lien\" in context_str:\n",
        "        return \"Vendor's Lien\"\n",
        "    elif \"special\" in context_str and \"warranty\" in context_str:\n",
        "        return \"Special Warranty\"\n",
        "    elif \"statutory\" in context_str:\n",
        "        return \"Statutory\"\n",
        "    elif \"warranty\" in context_str:\n",
        "        return \"General Warranty\"\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def classify_deed_type(text):\n",
        "    original_text = text\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    block_boundary_pattern = r\"(?s)(?:.*?<laysep@@##\\$\\$>|.+)\"\n",
        "    blocks = list(re.finditer(block_boundary_pattern, text_lower, re.DOTALL))\n",
        "\n",
        "    text_ptr = 0\n",
        "    heading = None\n",
        "\n",
        "    while heading is None:\n",
        "\n",
        "\n",
        "        if text_ptr >= len(text_lower):\n",
        "            return None\n",
        "\n",
        "        query_text = text_lower[text_ptr:]\n",
        "\n",
        "        deed_match = re.search(r\"\\bdeed\\b\", query_text, re.IGNORECASE)\n",
        "        if not deed_match:\n",
        "            return None\n",
        "\n",
        "        deed_start = text_ptr + deed_match.start()\n",
        "        deed_end = text_ptr + deed_match.end()\n",
        "\n",
        "\n",
        "        heading_block = None\n",
        "        for b in blocks:\n",
        "            if b.start() <= deed_start and b.end() >= deed_end:\n",
        "\n",
        "                if text_ptr < b.start():\n",
        "                  heading_block = b.group()\n",
        "                else:\n",
        "                  heading_block = text[text_ptr:b.end()]\n",
        "\n",
        "\n",
        "                break\n",
        "\n",
        "        if heading_block is None:\n",
        "            return None\n",
        "\n",
        "\n",
        "        heading_block = heading_block.lower()\n",
        "        words = re.findall(r\"\\b[\\w']+\\b\", heading_block)\n",
        "        try:\n",
        "            idx = words.index('deed')\n",
        "        except ValueError:\n",
        "            return None\n",
        "\n",
        "        context = words[max(0, idx - 5): idx + 6]\n",
        "        heading = match_keywords(context)\n",
        "\n",
        "        text_ptr = deed_end + 1\n",
        "\n",
        "    return heading\n",
        "\n",
        "\n",
        "counter = 0\n"
      ],
      "metadata": {
        "id": "Oip15MVMw4XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_wordy_blocks(text):\n",
        "    # Split using your custom separator or 3+ newlines\n",
        "    separator_pattern = r\"(?:laysep@@##\\$\\$>|(?:\\n\\s*){2,})\"\n",
        "    blocks = re.split(separator_pattern, text)\n",
        "\n",
        "    wordy_blocks = []\n",
        "    consecutive_words = r\"(?:[a-zA-Z]{2,}\\s){5,}\"\n",
        "\n",
        "    offset = 0  # Track position of each block in original text\n",
        "\n",
        "    for block in blocks:\n",
        "        block = block.strip()\n",
        "        if not block:\n",
        "            offset += 1  # Move past empty block (e.g. multiple separators)\n",
        "            continue\n",
        "\n",
        "        total_words = len(block.split())\n",
        "        total_lines = len(block.splitlines())\n",
        "        num_consecutive_words = len(re.findall(consecutive_words, block, re.IGNORECASE))\n",
        "\n",
        "        if num_consecutive_words >= 1:\n",
        "            start = text.find(block, offset)\n",
        "            end = start + len(block)\n",
        "            wordy_blocks.append((start, end))\n",
        "            offset = end\n",
        "        else:\n",
        "            offset += len(block)\n",
        "\n",
        "    return wordy_blocks"
      ],
      "metadata": {
        "id": "iFOGejubKOJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_matches(matches, numeric_pattern):\n",
        "  book_nums = []\n",
        "  page_nums= []\n",
        "  for m in matches:\n",
        "\n",
        "    numbers = re.findall(numeric_pattern, m)\n",
        "    book_num, page_num = numbers\n",
        "    book_nums.append(book_num)\n",
        "    page_nums.append(page_num)\n",
        "\n",
        "  if(len(set(book_nums)) ==  1):\n",
        "\n",
        "    if(len(set(page_nums)) ==  1):\n",
        "      return (book_num, page_num)\n",
        "\n",
        "    else:\n",
        "\n",
        "      if(all('-' not in s for s in page_nums)):\n",
        "\n",
        "        max_val = max(map(int, page_nums))\n",
        "        min_val = min(map(int, page_nums))\n",
        "        return (book_num, str(min_val)+\"-\"+str(max_val))\n",
        "\n",
        "      else:\n",
        "        valid_page_num = next(s for s in page_nums if '-' in s)\n",
        "        return (book_num, valid_page_num)\n",
        "  else:\n",
        "    return (book_nums[0], page_nums[0])"
      ],
      "metadata": {
        "id": "KsHEr7S4KC8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_document_info(document_text):\n",
        "\n",
        "\n",
        "  book = r\"(?i:book|bk|bk\\.|b|volume|vol|v)\"\n",
        "  page = r\"(?i:page|pg|pg\\.|p)\"\n",
        "  numeric_pattern = r\"\\d+(?:\\s*-\\s*\\d+)?\"\n",
        "\n",
        "  suffix = r\"(?:\\s*|no|no\\.|number|num|\\s*)?\"\n",
        "\n",
        "  key_value_separator = r\"(?:-|:|:-|\\s+)\"\n",
        "  key_value_pattern = rf\"(\\s*{key_value_separator}\\s*)\"\n",
        "\n",
        "  comma_separator = r\"\\s*,\\s*\"\n",
        "  and_separator = r\"\\s*and\\s*\"\n",
        "\n",
        "  word_separator = rf\"(?:{comma_separator}|{and_separator}|\\s+)\"\n",
        "\n",
        "  book_pattern = rf\"{book}{suffix}{key_value_pattern}{numeric_pattern}\"\n",
        "  page_pattern = rf\"{page}{suffix}{key_value_pattern}{numeric_pattern}\"\n",
        "\n",
        "  full_pattern = rf\"{book_pattern}{word_separator}{page_pattern}\"\n",
        "  book_page_matches = re.finditer(full_pattern, document_text, re.IGNORECASE)\n",
        "\n",
        "  wordy_blocks = find_wordy_blocks(document_text)\n",
        "  valid_matches = []\n",
        "\n",
        "  for match in book_page_matches:\n",
        "\n",
        "    is_valid_match = True\n",
        "\n",
        "    for wordy_block in wordy_blocks:\n",
        "      if match.start() >= wordy_block[0] and match.end() <= wordy_block[1]:\n",
        "        is_valid_match = False\n",
        "\n",
        "\n",
        "    if is_valid_match:\n",
        "      valid_matches.append(match.group())\n",
        "\n",
        "\n",
        "  return book_page_matches"
      ],
      "metadata": {
        "id": "84nN-57gJ5G4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}