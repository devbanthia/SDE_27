{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RUx3OitA6p3X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def find_entities_in_text(labels):\n",
        "    masks = []\n",
        "    entity_names = []\n",
        "\n",
        "    for i, label in enumerate(labels):\n",
        "        if i > 0 and labels[i] != 'O' and labels[i][2:] != labels[i-1][2:]:\n",
        "            entity_end = i\n",
        "            entity_names.append([labels[i][2:]])\n",
        "\n",
        "            while entity_end < len(labels) and labels[entity_end] != 'O':\n",
        "                entity_end += 1\n",
        "\n",
        "            mask = ([1] * (entity_end - i)) + ([0] * (len(labels) - entity_end + i))\n",
        "            mask = np.array(np.roll(mask, shift=i))\n",
        "            masks.append(mask)\n",
        "\n",
        "    return np.array(masks), entity_names\n",
        "\n",
        "\n",
        "\n",
        "def show_sample(input_ids, masks, entity_names):\n",
        "\n",
        "    all_entities = []\n",
        "    reconstructed_text = []\n",
        "    for i in range(len(masks)):\n",
        "\n",
        "        all_entities.append(entity_names[i])\n",
        "        boolean_mask = np.array(masks[i,:], dtype=bool)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(np.array(input_ids)[boolean_mask])\n",
        "        reconstructed_text.append(\" \".join(tokens).replace(\" ##\", \"\"))\n",
        "\n",
        "    return all_entities, reconstructed_text\n",
        "\n"
      ]
    }
  ]
}