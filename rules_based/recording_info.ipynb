{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def normalized(s):\n",
        "    parts = re.split(r'[-_]', str(s))\n",
        "    return parts[0] + parts[1].lstrip('0') if len(parts) == 2 else str(s)\n",
        "\n",
        "\n",
        "def search_adjacent_blocks(blocks, date_time_block_index, doc_num_pattern, mode):\n",
        "\n",
        "  current_block_index = date_time_block_index\n",
        "  potential_doc_nums = []\n",
        "  invalid_doc_nums = []\n",
        "\n",
        "  while current_block_index >= 0 and current_block_index >= date_time_block_index - 1 and current_block_index < len(blocks) and current_block_index <= date_time_block_index + 1:\n",
        "\n",
        "    current_block = blocks[current_block_index].group()\n",
        "    doc_num = re.finditer(doc_num_pattern, current_block)\n",
        "    invalid_doc_num = find_doc_num_matches(current_block)\n",
        "    invalid_doc_nums.extend(invalid_doc_num)\n",
        "    potential_doc_nums.extend(dn.group() for dn in doc_num)\n",
        "    current_block_index -= mode\n",
        "\n",
        "  potential_doc_nums = [re.sub(r\"\\s+\", \"\", s) for s in potential_doc_nums]\n",
        "  invalid_doc_nums = [re.sub(r\"\\s+\", \"\", s) for s in invalid_doc_nums]\n",
        "\n",
        "\n",
        "  return list(set(potential_doc_nums)-set(invalid_doc_nums))\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "def find_doc_num_matches(text):\n",
        "\n",
        "    doc_num_pattern = r\"(?:(?<!\\d)\\d{6,15}\\s+|(?<!\\d)\\d{4}\\s{0,4}-\\s{0,4}\\d{4,15}\\s+|\\s+\\d{4}\\s{0,4}_\\s{0,4}\\d{4,15}\\s+)\"\n",
        "    direct_doc_num_pattern = r\"(?:(?<!\\d)\\d{4,15}\\s+|(?<!\\d)\\d{4}\\s{0,4}-\\s{0,4}\\d{4,15}\\s+|\\s+\\d{4}\\s{0,4}_\\s{0,4}\\d{4,15}\\s+)\"\n",
        "    double_key_pattern = r\"(?:\\n[a-zA-Z.#]+\\s*[a-zA-Z.#]+)\"\n",
        "    key_val_sep = r\"(?:-|:|:-)\"\n",
        "    prefix = r\"(?:doc|doc\\.|document|instrument|instr\\.|instr|inst\\.|inst|recording|AFN|CFN|sequence|seq|seq\\.)\"\n",
        "    suffix = r\"(?:number|num(?:\\.)?|id|no(?:\\.)?|#)\"\n",
        "    explicit_doc_num_key_pattern = rf\"{prefix}\\s*{suffix}\"\n",
        "    doc_num_generic_pattern = rf\"(?:{double_key_pattern}\\s*{key_val_sep}\\s*{direct_doc_num_pattern})\"\n",
        "\n",
        "    potential_invalid_doc_num_matches = re.finditer(doc_num_generic_pattern, text, flags=re.IGNORECASE)\n",
        "    invalid_doc_nums = []\n",
        "\n",
        "    for m in potential_invalid_doc_num_matches:\n",
        "        keys = re.search(double_key_pattern, m.group(), flags=re.IGNORECASE)\n",
        "        is_true_match = re.search(explicit_doc_num_key_pattern, keys.group(), flags=re.IGNORECASE)\n",
        "        if is_true_match is None:\n",
        "            invalid_num = re.search(doc_num_pattern, m.group(), flags=re.IGNORECASE)\n",
        "            if invalid_num:\n",
        "                invalid_doc_nums.append(invalid_num.group())\n",
        "\n",
        "    return invalid_doc_nums\n",
        "\n",
        "\n",
        "\n",
        "def get_doc_num(text, date_time_span):\n",
        "\n",
        "\n",
        "  doc_num_pattern = r\"(?:(?<!\\d)\\d{6,15}\\s+|(?<!\\d)\\d{4}\\s{0,4}-\\s{0,4}\\d{4,15}\\s+|\\s+\\d{4}\\s{0,4}_\\s{0,4}\\d{4,15}\\s+)\"\n",
        "  direct_doc_num_pattern = r\"(?:(?<!\\d)\\d{4,15}\\s+|(?<!\\d)\\d{4}\\s{0,4}-\\s{0,4}\\d{4,15}\\s+|\\s+\\d{4}\\s{0,4}_\\s{0,4}\\d{4,15}\\s+)\"\n",
        "  block_boundary_pattern = r\"(?s)(?:.*?<laysep@@##\\$\\$>|.+)\"\n",
        "\n",
        "  prefix = r\"(?:doc(?:\\.)?|document|instrument|instr(?:\\.)?|inst(?:\\.)?|recording|AFN|CFN|sequence|seq(?:\\.)?)\"\n",
        "  suffix = r\"(?:number|num(?:\\.)?|id(?:\\.)?|no(?:\\.)?|#)\"\n",
        "  key_val_sep = r\"(?:-|:|:-|\\s*)\"\n",
        "  explicit_doc_num_pattern = rf\"{prefix}\\s*{suffix}(?:.{0,8})?\\s*{key_val_sep}\\s*{direct_doc_num_pattern}\"\n",
        "\n",
        "  explicit_doc_num = re.finditer(explicit_doc_num_pattern, text, flags=re.IGNORECASE)\n",
        "\n",
        "\n",
        "  blocks = re.finditer(block_boundary_pattern, text, re.DOTALL)\n",
        "  blocks = list(blocks)\n",
        "\n",
        "  if date_time_span is None:\n",
        "    return None\n",
        "\n",
        "  index, date_time_block = [(i, m) for i, m in enumerate(blocks) if (date_time_span[0] >= m.span()[0] and date_time_span[1] <= m.span()[1])][0]\n",
        "\n",
        "  preceding_blocks_doc_num = search_adjacent_blocks(blocks, index, doc_num_pattern, 1)\n",
        "  following_blocks_doc_num = search_adjacent_blocks(blocks, index, doc_num_pattern, -1)\n",
        "  doc_num = preceding_blocks_doc_num + following_blocks_doc_num\n",
        "  doc_num = [d for d in doc_num if d is not None]\n",
        "\n",
        "  if explicit_doc_num :\n",
        "    explicit_doc_num = [e.group() for e in explicit_doc_num]\n",
        "\n",
        "    cleaned_nums = [\n",
        "        re.sub(r'^\\D+', '', str(s))\n",
        "        for s in explicit_doc_num\n",
        "        if s and re.search(r'\\d', str(s))\n",
        "    ]\n",
        "\n",
        "    c = Counter(cleaned_nums)\n",
        "\n",
        "    if c:\n",
        "        most_common_item, frequency = c.most_common(1)[0]\n",
        "        if frequency > 1:\n",
        "            doc_num = [most_common_item]\n",
        "        else:\n",
        "            m = next(\n",
        "                (c_inner for c_inner in c if any(normalized(c_inner) == normalized(dn) for dn in doc_num)),\n",
        "                None\n",
        "            )\n",
        "            if m:\n",
        "                doc_num = [m]\n",
        "            else:\n",
        "                doc_num.extend(list(c))\n",
        "    else:\n",
        "        doc_num.extend(explicit_doc_num)\n",
        "  return doc_num\n",
        "\n",
        "text = \"\"\n",
        "date_time_match = find_date_time(text)\n",
        "if date_time_match is not None:\n",
        "  date_time_span = date_time_match.span()\n",
        "\n",
        "else:\n",
        "  date_time_span = None\n",
        "\n",
        "doc_num = get_doc_num(text, date_time_span)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Oip15MVMw4XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_matches(matches, numeric_pattern):\n",
        "  book_nums = []\n",
        "  page_nums= []\n",
        "  for m in matches:\n",
        "\n",
        "    numbers = re.findall(numeric_pattern, m)\n",
        "    book_num, page_num = numbers\n",
        "    book_nums.append(book_num)\n",
        "    page_nums.append(page_num)\n",
        "\n",
        "  if(len(set(book_nums)) ==  1):\n",
        "\n",
        "    if(len(set(page_nums)) ==  1):\n",
        "      return (book_num, page_num)\n",
        "\n",
        "    else:\n",
        "\n",
        "      if(all('-' not in s for s in page_nums)):\n",
        "\n",
        "        max_val = max(map(int, page_nums))\n",
        "        min_val = min(map(int, page_nums))\n",
        "        return (book_num, str(min_val)+\"-\"+str(max_val))\n",
        "\n",
        "      else:\n",
        "        valid_page_num = next(s for s in page_nums if '-' in s)\n",
        "        return (book_num, valid_page_num)\n",
        "  else:\n",
        "    return (book_nums[0], page_nums[0])"
      ],
      "metadata": {
        "id": "KsHEr7S4KC8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_pattern = r\"\\d+(?:\\s*-\\s*\\d+)?\"\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "def extract_document_info(filename, document_text):\n",
        "\n",
        "  header = classify_deed_type(document_text)\n",
        "\n",
        "  month = r\"(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\"\n",
        "  date_pattern = rf\"(?:(?:19|20)\\d{{2}}[-/\\.](?:0?[1-9]|1[0-2])[-/\\.](?:0?[1-9]|[12]\\d|3[01])\\b|(?:0?[1-9]|1[0-2])[-/\\.](?:0?[1-9]|[12]\\d|3[01])[-/\\.](?:19|20)\\d{{2}}\\b|(?:0?[1-9]|[12]\\d|3[01])[-/\\.](?:0?[1-9]|1[0-2])[-/\\.](?:19|20)\\d{{2}}\\b|(?:0?[1-9]|[12]\\d|3[01])(?:st|nd|rd|th)?(?:\\s*day)?(?:\\s*of)?\\s+{month}(?:\\s*[,\\/\\-]?\\s*)?(?:\\d{{4}})?\\b|{month}(?:\\s*[,\\/\\-]?\\s*)?(?:0?[1-9]|[12]\\d|3[01])(?:st|nd|rd|th)?(?:\\s*[,\\/\\-]?\\s*)(?:\\d{{4}})?\\b|(?:19|20)\\d{{2}}(?:\\s*[,\\/\\-]?\\s*)?{month}(?:\\s*[,\\/\\-]?\\s*)?(?:0?[1-9]|[12]\\d|3[01])(?:st|nd|rd|th)?\\b|(?:0?[1-9]|[12]\\d|3[01])\\.(?:0?[1-9]|1[0-2])\\.(?:19|20)\\d{{2}})\"\n",
        "  time_pattern = r\"(?:[01]?\\d|2[0-3]):[0-5]\\d(?::[0-5]\\d)?(?:\\s*[APap][Mm])?|\\b(?:[1-9]|1[0-2])(?:[:.][0-5]\\d){1,2}\\s*[APap][Mm]\"\n",
        "\n",
        "  date_time_separator = r\"(?:\\s*-\\s*|\\s+at\\s+|\\s*,\\s*|\\s*|.{0,20})\"\n",
        "  date_time_pattern = rf\"(?:{date_pattern})(?:{date_time_separator})(?:{time_pattern})\"\n",
        "\n",
        "\n",
        "  book = r\"(?:book|bk(?:\\.)?|b(?:\\.)?|volume|vol(?:\\.)?|v(?:\\.)?)\"\n",
        "  page = r\"(?:page(?:s)?|pg(?:\\.)?(?:s)?|p(?:\\.)?(?:s)?)\"\n",
        "  numeric_pattern = r\"\\d+(?:\\s*-\\s*\\d+)?\"\n",
        "\n",
        "  suffix = r\"(?:no(?:\\.)?|number|num(?:\\.)?|\\s*)?\"\n",
        "\n",
        "  key_value_separator = r\"(?:-|:|:-|\\s+)?\"\n",
        "  key_value_pattern = rf\"(?:\\s*{key_value_separator}\\s*)\"\n",
        "\n",
        "  comma_separator = r\"(?:\\s*,\\s*)\"\n",
        "  and_separator = r\"(?:\\s*and\\s*)\"\n",
        "\n",
        "  word_separator = rf\"(?:{comma_separator}|{and_separator}|\\s+|.{0,20})\"\n",
        "  #fix word separator\n",
        "\n",
        "  book_pattern = rf\"(?:{book}{suffix}{key_value_pattern}{numeric_pattern})\"\n",
        "  page_pattern = rf\"(?:{page}{suffix}{key_value_pattern}{numeric_pattern})\"\n",
        "\n",
        "  full_pattern = rf\"{book_pattern}{word_separator}{page_pattern}\"\n",
        "  book_page_matches = re.finditer(full_pattern, document_text, re.IGNORECASE)\n",
        "\n",
        "  date_time_match = re.search(date_time_pattern, document_text, re.IGNORECASE)\n",
        "\n",
        "  all_recording_dates = re.finditer(date_time_pattern, document_text, re.IGNORECASE)\n",
        "\n",
        "  if date_time_match is not None:\n",
        "    date_time_span = date_time_match.span()\n",
        "\n",
        "  else:\n",
        "    date_time_span = None\n",
        "\n",
        "\n",
        "  if date_time_span is not None:\n",
        "\n",
        "    block_boundary_pattern = r\"(?s)(?:.*?<laysep@@##\\$\\$>|.+)\"\n",
        "    blocks = re.finditer(block_boundary_pattern, document_text, re.DOTALL)\n",
        "    blocks = list(blocks)\n",
        "    index, date_time_block = [(i, m) for i, m in enumerate(blocks) if (date_time_span[0] >= m.span()[0] and date_time_span[1] <= m.span()[1])][0]\n",
        "\n",
        "    if index > 0 and index < len(blocks) - 1:\n",
        "      valid_book_page_span = (blocks[index-1].span()[0], blocks[index+1].span()[1])\n",
        "    elif index == 0:\n",
        "      valid_book_page_span = (blocks[index].span()[0], blocks[index+1].span()[1])\n",
        "    else:\n",
        "      valid_book_page_span = (blocks[index-1].span()[0], blocks[index].span()[1])\n",
        "\n",
        "\n",
        "\n",
        "    valid_book_page_matches = [m.group() for m in book_page_matches if m.span()[0] >= valid_book_page_span[0] and m.span()[1] <= valid_book_page_span[1]]\n",
        "\n",
        "  else:\n",
        "    valid_book_page_matches = []\n",
        "\n",
        "\n",
        "  doc_num = get_doc_num(document_text, date_time_span)\n",
        "  recording_date = None\n",
        "\n",
        "  if date_time_match is not None:\n",
        "    recording_date = re.search(date_pattern, date_time_match.group(), re.IGNORECASE)\n",
        "    recording_date = recording_date.group()\n",
        "\n",
        "  book_num = None\n",
        "  page_num = None\n",
        "\n",
        "  if len(valid_book_page_matches) > 0:\n",
        "    book_num, page_num = filter_matches(valid_book_page_matches, numeric_pattern)\n",
        "\n",
        "  return (book_num, page_num, recording_date, doc_num)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "84nN-57gJ5G4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}